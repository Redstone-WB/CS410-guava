{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## To use np.load, downgrade numpy version\n",
    "# !pip uninstall numpy --y\n",
    "# !pip install --upgrade numpy==1.16.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable notebook\n",
    "\n",
    "- CS410 Final Project\n",
    "- members : Changsoo Kim, Hongseok Ha\n",
    "- updated : 2020/12/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from importlib import reload\n",
    "# import lda\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. References\n",
    "\n",
    "- Code and Dataset from a homepage of the original author : http://sifaka.cs.uiuc.edu/~wang296/\n",
    "- Python code (Especially for data preparation, before LDA) : https://github.com/tonyzhang1231/LARA_Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating Corpus and Vocabs\n",
    "\n",
    "- stopwords >> nltk package\n",
    "- Review Contents >> Parsing sentences & Computing frequencies (using nltk FreqDist)\n",
    "- Output : yelp_mp1_corpus.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CreateVocab import *\n",
    "from src.Structure import *\n",
    "from src.lda_preproc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_obj = CreateVocab()  # create an instance\n",
    "# cv_obj.create_stopwords()  # create a list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file No.1\n",
      "loading file No.2\n",
      "loading file No.3\n",
      "loading file No.4\n",
      "loading file No.5\n",
      "loading file No.6\n",
      "loading file No.7\n",
      "loading file No.8\n",
      "loading file No.9\n",
      "loading file No.10\n",
      "loading file No.11\n",
      "loading file No.12\n",
      "loading file No.13\n",
      "loading file No.14\n",
      "loading file No.15\n",
      "loading file No.16\n",
      "loading file No.17\n",
      "loading file No.18\n",
      "loading file No.19\n",
      "loading file No.20\n",
      "loading file No.21\n",
      "loading file No.22\n",
      "loading file No.23\n",
      "loading file No.24\n",
      "loading file No.25\n",
      "loading file No.26\n",
      "loading file No.27\n",
      "succeed saving to file ./data/yelp_mp1_corpus\n"
     ]
    }
   ],
   "source": [
    "# suffix = \"json\"\n",
    "# folder = \"./data/yelp mp1 data/\"\n",
    "# cv_obj.read_data(folder, suffix)\n",
    "# cv_obj.create_vocab()\n",
    "\n",
    "# # save it to a file\n",
    "# savefilepath = \"./data/yelp_mp1_corpus\"\n",
    "# cv_obj.save_to_file(savefilepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Assigning Corpus to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_obj = CreateVocab()\n",
    "loadfilepath = \"./data/yelp_mp1_corpus.npy\"\n",
    "\n",
    "## load from yelp_mpl_corpus.npy \n",
    "(cv_obj.corpus, cv_obj.Vocab, cv_obj.Count, cv_obj.VocabDict) = np.load(loadfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'50\", \"'best\", \"'bruschetta\", \"'burb\", \"'caus\", \"'chef\", \"'chicken\", \"'corn\", \"'cue\", \"'do\"]\n",
      "[6, 14, 6, 11, 39, 6, 36, 48, 6, 10]\n"
     ]
    }
   ],
   "source": [
    "# check the data\n",
    "print(cv_obj.Vocab[:10])\n",
    "print(cv_obj.Count[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warning : takes more than 15 minutes ##\n",
    "data = Corpus(cv_obj.corpus, cv_obj.Vocab, cv_obj.Count, cv_obj.VocabDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Using LDA to find latent topics\n",
    "\n",
    "- Child of Corpus class, LDA_utils class\n",
    "- Input : Corpus\n",
    "- Output : LDA outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['src.lda_preproc'])\n",
    "from src.lda_preproc import LDA_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant 7lnOgOMd7zys3bFfWY_jIw Done!\n",
      "Restaurant 0qnMSq3gYhGDesZKxNgAkQ Done!\n",
      "Restaurant 8d-RAa59tgV06VRa5SOe9A Done!\n",
      "Restaurant 8y00IHK9sbA1Zhl2E9hmpA Done!\n",
      "Restaurant A9xPHLcWtRgK6Mf4-ksBrw Done!\n",
      "Restaurant 9N0YqwhE1qwU4OmhzwGjtA Done!\n",
      "Restaurant 8y00IHK9sbA1Zhl2E9hmpA Done!\n",
      "Restaurant d5YWKrP-zG74nqOYzHn7Zg Done!\n",
      "Restaurant 8d-RAa59tgV06VRa5SOe9A Done!\n",
      "Restaurant 7pezxyAK-7l5Yfr7W7fFQQ Done!\n",
      "Restaurant b7jDtbG7UloYasZ9sVXHWg Done!\n",
      "Restaurant 4lgk5AJvmoXPrfSlCyjiQg Done!\n",
      "Restaurant 0qnMSq3gYhGDesZKxNgAkQ Done!\n",
      "Restaurant 7lnOgOMd7zys3bFfWY_jIw Done!\n",
      "Restaurant 9GVazUhx0dYB-_H0hlgB5w Done!\n",
      "Restaurant 3OLZOlqgOXdqY0uwxcOTfw Done!\n",
      "Restaurant CvmAN25laBbwZTqmlEAR1Q Done!\n",
      "Restaurant b7jDtbG7UloYasZ9sVXHWg Done!\n",
      "Restaurant 3VCZ21-DIw7voVexDMXDSA Done!\n",
      "Restaurant 7pezxyAK-7l5Yfr7W7fFQQ Done!\n",
      "Restaurant aq_UTxlYvMNEN-urxbUddA Done!\n",
      "Restaurant 9GVazUhx0dYB-_H0hlgB5w Done!\n",
      "Restaurant 9N0YqwhE1qwU4OmhzwGjtA Done!\n",
      "Restaurant 9IRdWhDNo2T6vyMLwrQdMw Done!\n",
      "Restaurant 3VCZ21-DIw7voVexDMXDSA Done!\n",
      "Restaurant 6CvMYmV0Uw4Y4G7NpvTgfg Done!\n",
      "Restaurant AZrLjmV0A2TzOCkZ6CU-Fg Done!\n",
      "48079\n",
      "(48079, 12311)\n"
     ]
    }
   ],
   "source": [
    "## To make a doc-term matrix\n",
    "\n",
    "data_lda = LDA_utils(data)\n",
    "print(data_lda.num_reviews_tot)\n",
    "print(data_lda.doc_term_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5601, 10195, 17492, 19825, 25420, 25657, 29272, 30485, 32744,\n",
       "       36314, 38970, 39207, 46593])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Checking all-zero rows\n",
    "np.where(~data_lda.doc_term_matrix.any(axis=1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 48079\n",
      "INFO:lda:vocab_size: 12311\n",
      "INFO:lda:n_words: 3221134\n",
      "INFO:lda:n_topics: 10\n",
      "INFO:lda:n_iter: 1500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -32111304\n",
      "INFO:lda:<10> log likelihood: -27752659\n",
      "INFO:lda:<20> log likelihood: -26041166\n",
      "INFO:lda:<30> log likelihood: -25479626\n",
      "INFO:lda:<40> log likelihood: -25231025\n",
      "INFO:lda:<50> log likelihood: -25088022\n",
      "INFO:lda:<60> log likelihood: -25011676\n",
      "INFO:lda:<70> log likelihood: -24967390\n",
      "INFO:lda:<80> log likelihood: -24925254\n",
      "INFO:lda:<90> log likelihood: -24896038\n",
      "INFO:lda:<100> log likelihood: -24871857\n",
      "INFO:lda:<110> log likelihood: -24849649\n",
      "INFO:lda:<120> log likelihood: -24835875\n",
      "INFO:lda:<130> log likelihood: -24823937\n",
      "INFO:lda:<140> log likelihood: -24811676\n",
      "INFO:lda:<150> log likelihood: -24803809\n",
      "INFO:lda:<160> log likelihood: -24794110\n",
      "INFO:lda:<170> log likelihood: -24788604\n",
      "INFO:lda:<180> log likelihood: -24784119\n",
      "INFO:lda:<190> log likelihood: -24775157\n",
      "INFO:lda:<200> log likelihood: -24764076\n",
      "INFO:lda:<210> log likelihood: -24768487\n",
      "INFO:lda:<220> log likelihood: -24762006\n",
      "INFO:lda:<230> log likelihood: -24756534\n",
      "INFO:lda:<240> log likelihood: -24752419\n",
      "INFO:lda:<250> log likelihood: -24746823\n",
      "INFO:lda:<260> log likelihood: -24752165\n",
      "INFO:lda:<270> log likelihood: -24749510\n",
      "INFO:lda:<280> log likelihood: -24747901\n",
      "INFO:lda:<290> log likelihood: -24748590\n",
      "INFO:lda:<300> log likelihood: -24744665\n",
      "INFO:lda:<310> log likelihood: -24741552\n",
      "INFO:lda:<320> log likelihood: -24743184\n",
      "INFO:lda:<330> log likelihood: -24743831\n",
      "INFO:lda:<340> log likelihood: -24741951\n",
      "INFO:lda:<350> log likelihood: -24738414\n",
      "INFO:lda:<360> log likelihood: -24734844\n",
      "INFO:lda:<370> log likelihood: -24734641\n",
      "INFO:lda:<380> log likelihood: -24735820\n",
      "INFO:lda:<390> log likelihood: -24735807\n",
      "INFO:lda:<400> log likelihood: -24734753\n",
      "INFO:lda:<410> log likelihood: -24730140\n",
      "INFO:lda:<420> log likelihood: -24731737\n",
      "INFO:lda:<430> log likelihood: -24728610\n",
      "INFO:lda:<440> log likelihood: -24726473\n",
      "INFO:lda:<450> log likelihood: -24730764\n",
      "INFO:lda:<460> log likelihood: -24729349\n",
      "INFO:lda:<470> log likelihood: -24732327\n",
      "INFO:lda:<480> log likelihood: -24729570\n",
      "INFO:lda:<490> log likelihood: -24732055\n",
      "INFO:lda:<500> log likelihood: -24724018\n",
      "INFO:lda:<510> log likelihood: -24720265\n",
      "INFO:lda:<520> log likelihood: -24726626\n",
      "INFO:lda:<530> log likelihood: -24725128\n",
      "INFO:lda:<540> log likelihood: -24720517\n",
      "INFO:lda:<550> log likelihood: -24723462\n",
      "INFO:lda:<560> log likelihood: -24726840\n",
      "INFO:lda:<570> log likelihood: -24726452\n",
      "INFO:lda:<580> log likelihood: -24720850\n",
      "INFO:lda:<590> log likelihood: -24721665\n",
      "INFO:lda:<600> log likelihood: -24722293\n",
      "INFO:lda:<610> log likelihood: -24719073\n",
      "INFO:lda:<620> log likelihood: -24720532\n",
      "INFO:lda:<630> log likelihood: -24719440\n",
      "INFO:lda:<640> log likelihood: -24722925\n",
      "INFO:lda:<650> log likelihood: -24719414\n",
      "INFO:lda:<660> log likelihood: -24719995\n",
      "INFO:lda:<670> log likelihood: -24721401\n",
      "INFO:lda:<680> log likelihood: -24725611\n",
      "INFO:lda:<690> log likelihood: -24726133\n",
      "INFO:lda:<700> log likelihood: -24725620\n",
      "INFO:lda:<710> log likelihood: -24723387\n",
      "INFO:lda:<720> log likelihood: -24721969\n",
      "INFO:lda:<730> log likelihood: -24723801\n",
      "INFO:lda:<740> log likelihood: -24723143\n",
      "INFO:lda:<750> log likelihood: -24724923\n",
      "INFO:lda:<760> log likelihood: -24723612\n",
      "INFO:lda:<770> log likelihood: -24722742\n",
      "INFO:lda:<780> log likelihood: -24724952\n",
      "INFO:lda:<790> log likelihood: -24726074\n",
      "INFO:lda:<800> log likelihood: -24715906\n",
      "INFO:lda:<810> log likelihood: -24718129\n",
      "INFO:lda:<820> log likelihood: -24727043\n",
      "INFO:lda:<830> log likelihood: -24722606\n",
      "INFO:lda:<840> log likelihood: -24722829\n",
      "INFO:lda:<850> log likelihood: -24719795\n",
      "INFO:lda:<860> log likelihood: -24720587\n",
      "INFO:lda:<870> log likelihood: -24723773\n",
      "INFO:lda:<880> log likelihood: -24722382\n",
      "INFO:lda:<890> log likelihood: -24727186\n",
      "INFO:lda:<900> log likelihood: -24723976\n",
      "INFO:lda:<910> log likelihood: -24726785\n",
      "INFO:lda:<920> log likelihood: -24728293\n",
      "INFO:lda:<930> log likelihood: -24724736\n",
      "INFO:lda:<940> log likelihood: -24720358\n",
      "INFO:lda:<950> log likelihood: -24722360\n",
      "INFO:lda:<960> log likelihood: -24720038\n",
      "INFO:lda:<970> log likelihood: -24720014\n",
      "INFO:lda:<980> log likelihood: -24721975\n",
      "INFO:lda:<990> log likelihood: -24715749\n",
      "INFO:lda:<1000> log likelihood: -24720173\n",
      "INFO:lda:<1010> log likelihood: -24716364\n",
      "INFO:lda:<1020> log likelihood: -24718356\n",
      "INFO:lda:<1030> log likelihood: -24722658\n",
      "INFO:lda:<1040> log likelihood: -24717586\n",
      "INFO:lda:<1050> log likelihood: -24714278\n",
      "INFO:lda:<1060> log likelihood: -24715553\n",
      "INFO:lda:<1070> log likelihood: -24720792\n",
      "INFO:lda:<1080> log likelihood: -24718580\n",
      "INFO:lda:<1090> log likelihood: -24724999\n",
      "INFO:lda:<1100> log likelihood: -24715952\n",
      "INFO:lda:<1110> log likelihood: -24722273\n",
      "INFO:lda:<1120> log likelihood: -24722293\n",
      "INFO:lda:<1130> log likelihood: -24713294\n",
      "INFO:lda:<1140> log likelihood: -24721822\n",
      "INFO:lda:<1150> log likelihood: -24722541\n",
      "INFO:lda:<1160> log likelihood: -24724004\n",
      "INFO:lda:<1170> log likelihood: -24715774\n",
      "INFO:lda:<1180> log likelihood: -24718959\n",
      "INFO:lda:<1190> log likelihood: -24718617\n",
      "INFO:lda:<1200> log likelihood: -24718854\n",
      "INFO:lda:<1210> log likelihood: -24715121\n",
      "INFO:lda:<1220> log likelihood: -24717420\n",
      "INFO:lda:<1230> log likelihood: -24720780\n",
      "INFO:lda:<1240> log likelihood: -24721386\n",
      "INFO:lda:<1250> log likelihood: -24717417\n",
      "INFO:lda:<1260> log likelihood: -24715722\n",
      "INFO:lda:<1270> log likelihood: -24714353\n",
      "INFO:lda:<1280> log likelihood: -24717450\n",
      "INFO:lda:<1290> log likelihood: -24719385\n",
      "INFO:lda:<1300> log likelihood: -24720054\n",
      "INFO:lda:<1310> log likelihood: -24716503\n",
      "INFO:lda:<1320> log likelihood: -24720596\n",
      "INFO:lda:<1330> log likelihood: -24713258\n",
      "INFO:lda:<1340> log likelihood: -24718367\n",
      "INFO:lda:<1350> log likelihood: -24717132\n",
      "INFO:lda:<1360> log likelihood: -24723780\n",
      "INFO:lda:<1370> log likelihood: -24715940\n",
      "INFO:lda:<1380> log likelihood: -24719968\n",
      "INFO:lda:<1390> log likelihood: -24714834\n",
      "INFO:lda:<1400> log likelihood: -24718755\n",
      "INFO:lda:<1410> log likelihood: -24717517\n",
      "INFO:lda:<1420> log likelihood: -24718967\n",
      "INFO:lda:<1430> log likelihood: -24720156\n",
      "INFO:lda:<1440> log likelihood: -24717705\n",
      "INFO:lda:<1450> log likelihood: -24719484\n",
      "INFO:lda:<1460> log likelihood: -24720271\n",
      "INFO:lda:<1470> log likelihood: -24720229\n",
      "INFO:lda:<1480> log likelihood: -24720616\n",
      "INFO:lda:<1490> log likelihood: -24722941\n",
      "INFO:lda:<1499> log likelihood: -24717182\n"
     ]
    }
   ],
   "source": [
    "## LDA Model Fitting\n",
    "## takes more than 5 minutes to train\n",
    "## Using lda package\n",
    "\n",
    "data_lda.model_fit(n_topics = 10, n_iter = 1500, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48079, 10)\n",
      "[0.00434783 0.00434783 0.87391304 0.00434783 0.00434783 0.09130435\n",
      " 0.00434783 0.00434783 0.00434783 0.00434783]\n"
     ]
    }
   ],
   "source": [
    "## doc_topic matrix\n",
    "## doc = review, doc consists of multiple sentences\n",
    "## words can be substituted, by using data.Vocabdict (implemented in create_doc_term_matrix)\n",
    "\n",
    "print(data_lda.model.doc_topic_.shape)\n",
    "print(data_lda.model.doc_topic_[0, :])  ## first document >> topic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: waistlin lobstah role n'chees pla oy steadili goo gestur measur\n",
      "Topic 1: n'chees urth ordeal foo waistlin tabasco tim gestur worthwhil lightweight\n",
      "Topic 2: pastor- sandwhich n'chees goo lane delet cantanker lightweight besid pla\n",
      "Topic 3: tha foo disgustingli n'chees goo pla restaraunt besid ordeal ribs.th\n",
      "Topic 4: goo pla bbblt n'chees doesnt chica hostil brisk cheerwin ri\n",
      "Topic 5: foo goo breaker eg n'chees chick pla ordeal gnosh to.th\n",
      "Topic 6: tackl goo stapl pla n'chees bife gestur foo drill greasiest\n",
      "Topic 7: chocohol despit hostil goo n'chees cheerwin ordeal dumpi ongo lightweight\n",
      "Topic 8: fret chick goo n'chees cocain pore wine/b lightweight pla saturday\n",
      "Topic 9: foo pla greasiest goo server/bartend gnosh n'chees restaraunt gestur tim\n"
     ]
    }
   ],
   "source": [
    "## Describe topics (top 10 words)\n",
    "\n",
    "data_lda.describe_topics(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc-term matrix Shape : (48079, 12311)\n",
      "Doc-topic matrix Shape : (48079, 10)\n",
      "topic-word matrix Shape : (10, 12311)\n"
     ]
    }
   ],
   "source": [
    "## Key matrices\n",
    "print(\"Doc-term matrix Shape : {0}\".format(data_lda.doc_term_matrix.shape))\n",
    "print(\"Doc-topic matrix Shape : {0}\".format(data_lda.model.doc_topic_.shape))\n",
    "print(\"topic-word matrix Shape : {0}\".format(data_lda.model.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data_lda.describe_single_doc(0)\n",
    "## data_lda.describe_multiple_doc(0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Calculate inner-topic similarity\n",
    "\n",
    "1. Topic Coherence : Given a topic k, the PMI score is calculated by the following equation :\n",
    "2. N : number of the most probable words in this topic (default = 20?)\n",
    "\n",
    "$$ C_K = \\frac{2}{N(N-1)} \\sum_{1\\le i<j \\le N}log \\frac{p(w_i, w_j)}{p(w_i)p(w_j)}$$ \n",
    "\n",
    "--- STILL IMPLEMENTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 12311)\n"
     ]
    }
   ],
   "source": [
    "## Num of Topics * Num of Words >> Topic distribution\n",
    "print(data_lda.model.components_.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1044"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum((data_lda.doc_term_matrix[:, 11823] > 0) & (data_lda.doc_term_matrix[:, 6580] > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_topics = 10\n",
    "# for topic_idx in range(len(n_topics)):\n",
    "#     all_word_cnts = sum(sum(data_lda.doc_term_matrix > 0))\n",
    "#     words_now_idx = top_k_inds[topic_idx,:]\n",
    "#     for i in word_now_idx:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3. KL divergence\n",
    "\n",
    "1. LARAM 논문에서는 trip advisior에서 제공하는 7개의 aspects를 Bootstrapping으로 확장하여 LDA를 적용. \n",
    "2. 1을 ground-truth로 가정하고 방법론들 간 성능을 비교 하였음 \n",
    "3. 논문 구현이 목적이고 topic modeling에 LDA를 사용 하였으므로, KL-divergence는 skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes Below are not used ----------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (Previous) Using Bootstrap method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2. using bootstrapping method\n",
    "# if loading data from saved files\n",
    "cv_obj = CreateVocab()\n",
    "loadfilepath = \"./data/yelp_mp1_corpus.npy\"\n",
    "\n",
    "## yelp_mpl_corpus.npy 파일에 저장한 변수들을 그대로 불러 옴.\n",
    "(cv_obj.corpus, cv_obj.Vocab, cv_obj.Count, cv_obj.VocabDict) = np.load(loadfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'50\", \"'best\", \"'bruschetta\", \"'burb\", \"'caus\", \"'chef\", \"'chicken\", \"'corn\", \"'cue\", \"'do\"]\n",
      "[6, 14, 6, 11, 39, 6, 36, 48, 6, 10]\n"
     ]
    }
   ],
   "source": [
    "# cv_obj.corpus[0]\n",
    "print(cv_obj.Vocab[:10])\n",
    "print(cv_obj.Count[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = Corpus(cv_obj.corpus, cv_obj.Vocab, cv_obj.Count,cv_obj.VocabDict)\n",
    "# load_Aspect_Terms(BSanalyzer,loadfilepath,VocabDict)\n",
    "\n",
    "# otherwise\n",
    "## structure.py 에 포함된 Corpus class\n",
    "## 변수 저장\n",
    "data = Corpus(cv_obj.corpus, cv_obj.Vocab, cv_obj.Count, cv_obj.VocabDict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 아래 Bootstrapping 파트를 LDA로 갈아 끼우면 LARAM 과 유사하게 동작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'50\", \"'best\", \"'bruschetta\", \"'burb\"]\n",
      "[6, 14, 6, 11]\n"
     ]
    }
   ],
   "source": [
    "print(data.Vocab[:4])\n",
    "print(data.VocabTF[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "7lnOgOMd7zys3bFfWY_jIw\n",
      "Langer’s\n",
      "$$\n",
      "2171\n",
      "2171\n",
      "<FreqDist with 6 samples and 6 outcomes>\n",
      "6\n",
      "[4]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(data.Restaurants))\n",
    "print(data.Restaurants[0].RestaurantID)\n",
    "print(data.Restaurants[0].Name)\n",
    "print(data.Restaurants[0].Price)\n",
    "print(len(data.Restaurants[0].Reviews))\n",
    "print(data.Restaurants[0].NumOfReviews)\n",
    "\n",
    "\n",
    "##Review에서 stn(content를 문장, 단어로 tokenize 하는 함수인 parse_to_sentence_UseVocab)\n",
    "print(data.Restaurants[0].Reviews[0].Stns[0].stn)\n",
    "print(data.Restaurants[0].Reviews[0].Stns[0].unilength)\n",
    "print(data.Restaurants[0].Reviews[0].Stns[0].label)\n",
    "print(data.Restaurants[0].Reviews[0].NumOfUniWord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드 실행 계속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## structure.py 의 Bootstrapping class\n",
    "BSanalyzer = Bootstrapping() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect Keywords loading completed\n"
     ]
    }
   ],
   "source": [
    "loadfilepath = \"./init_aspect_word.txt\"\n",
    "load_Aspect_Terms(BSanalyzer, loadfilepath, cv_obj.VocabDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend, price, quality, worth, food \n",
      "\n",
      "service, minute, wait, staff, order\n",
      "\n",
      "location, park, atmosphere, place, room\n",
      "\n",
      "pork, chicken, beef, rib\n",
      "\n",
      "shrimp, oyster, egg, sauce, bread\n"
     ]
    }
   ],
   "source": [
    "### Aspect Words\n",
    "f = open(loadfilepath, \"r\")\n",
    "for l in f:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9032\n",
      "8684\n",
      "8861\n"
     ]
    }
   ],
   "source": [
    "print(data.VocabDict['recommend'])\n",
    "print(data.VocabDict['price'])\n",
    "print(data.VocabDict['qualiti'])  ## stemming 한 뒤의 결과이기 때문에 qualiti 가 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9032,\n",
       "  8684,\n",
       "  8861,\n",
       "  12137,\n",
       "  4530,\n",
       "  5447,\n",
       "  10971,\n",
       "  8577,\n",
       "  9004,\n",
       "  4975,\n",
       "  4663,\n",
       "  8058,\n",
       "  8677,\n",
       "  1422,\n",
       "  8998,\n",
       "  9171,\n",
       "  9261,\n",
       "  7519,\n",
       "  8693,\n",
       "  5614,\n",
       "  10450,\n",
       "  9955,\n",
       "  7506,\n",
       "  3272,\n",
       "  2685,\n",
       "  6641,\n",
       "  936,\n",
       "  3147,\n",
       "  10002,\n",
       "  9881,\n",
       "  7985,\n",
       "  11843,\n",
       "  436,\n",
       "  3103,\n",
       "  11665],\n",
       " [9737,\n",
       "  7153,\n",
       "  11824,\n",
       "  10356,\n",
       "  7904,\n",
       "  10765,\n",
       "  5582,\n",
       "  4671,\n",
       "  6610,\n",
       "  9659,\n",
       "  11606,\n",
       "  11099,\n",
       "  6538,\n",
       "  11160,\n",
       "  11832,\n",
       "  9735,\n",
       "  5569,\n",
       "  1204,\n",
       "  1251,\n",
       "  11188,\n",
       "  1170,\n",
       "  491,\n",
       "  8989,\n",
       "  11838,\n",
       "  4398,\n",
       "  8152,\n",
       "  7123,\n",
       "  1164,\n",
       "  2133,\n",
       "  9532,\n",
       "  10799,\n",
       "  1589,\n",
       "  5390,\n",
       "  7877,\n",
       "  4860],\n",
       " [6584,\n",
       "  8137,\n",
       "  1237,\n",
       "  8434,\n",
       "  9357,\n",
       "  10507,\n",
       "  8054,\n",
       "  6638,\n",
       "  12036,\n",
       "  11637,\n",
       "  6661,\n",
       "  1722,\n",
       "  781,\n",
       "  4736,\n",
       "  3174,\n",
       "  6726,\n",
       "  4378,\n",
       "  11290,\n",
       "  623,\n",
       "  6567,\n",
       "  9504,\n",
       "  9349,\n",
       "  2377,\n",
       "  6720,\n",
       "  4952,\n",
       "  6324,\n",
       "  5671,\n",
       "  6363,\n",
       "  2410,\n",
       "  3285,\n",
       "  2172,\n",
       "  7412,\n",
       "  3508,\n",
       "  8576,\n",
       "  3592],\n",
       " [8563,\n",
       "  2418,\n",
       "  1523,\n",
       "  9255,\n",
       "  11812,\n",
       "  2887,\n",
       "  1562,\n",
       "  8819,\n",
       "  9457,\n",
       "  6006,\n",
       "  1934,\n",
       "  2373,\n",
       "  10933,\n",
       "  1862,\n",
       "  9843,\n",
       "  6647,\n",
       "  6146,\n",
       "  10350,\n",
       "  10780,\n",
       "  6278,\n",
       "  3690,\n",
       "  4441,\n",
       "  4402,\n",
       "  8179,\n",
       "  10081,\n",
       "  890,\n",
       "  10007,\n",
       "  6943,\n",
       "  3198,\n",
       "  7230,\n",
       "  8109,\n",
       "  9043,\n",
       "  9856,\n",
       "  11218],\n",
       " [9867,\n",
       "  8038,\n",
       "  3858,\n",
       "  9545,\n",
       "  1876,\n",
       "  9432,\n",
       "  1575,\n",
       "  7495,\n",
       "  8509,\n",
       "  1366,\n",
       "  4652,\n",
       "  11139,\n",
       "  9426,\n",
       "  9625,\n",
       "  11165,\n",
       "  8181,\n",
       "  5501,\n",
       "  4643,\n",
       "  3687,\n",
       "  10735,\n",
       "  3057,\n",
       "  9992,\n",
       "  11010,\n",
       "  7853,\n",
       "  2687,\n",
       "  3459,\n",
       "  3753,\n",
       "  10195,\n",
       "  303,\n",
       "  1396,\n",
       "  6885,\n",
       "  8596,\n",
       "  10125,\n",
       "  3059,\n",
       "  11645]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## aspect words에 대한 frequencies가 VocabDict의 value이므로,, load_Aspect_Term 함수에서 해당 값을 가져옴\n",
    "BSanalyzer.Aspect_Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sktelecom/Desktop/LARAM/Ref/LARA_Python/src/Structure.py:137: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return N * (A * D - B * C) * (A * D - B * C) / aDF / (B + D) / tDF / (C + D)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete iteration 1/5\n",
      "complete iteration 2/5\n",
      "complete iteration 3/5\n",
      "complete iteration 4/5\n",
      "complete iteration 5/5\n"
     ]
    }
   ],
   "source": [
    "# expand aspect keywords >> 어떻게 확장하나??\n",
    "## Bootstrapping class의 sentence_label() 함수 : \n",
    "Add_Aspect_Keywords(BSanalyzer, 5, 5, data)\n",
    "\n",
    "savefilepath = './output/final_aspect_words.txt'\n",
    "save_Aspect_Keywords_to_file(BSanalyzer, savefilepath, cv_obj.Vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommend, price, qualiti, worth, food, highli, thai, portion, reason, good, fri, pad, pretti, bar, realli, reserv, rice, next, pricey, huge, sticki, size, network, deMcsrch.finit, cole, lotu, allig, damn, slice, siam, overal, walk, 30, curri, vega, \n",
      "\n",
      "\n",
      "\n",
      "servic, minut, wait, staff, order, tabl, hour, friendli, long, seat, us, time, line, told, waiter, server, hostess, ask, attent, took, arriv, 45, readi, waitress, first, parti, min, around, call, sat, take, best, help, open, get, \n",
      "\n",
      "\n",
      "\n",
      "locat, park, atmospher, place, room, street, pack, lot, wicker, valid, love, block, across, fun, date, macarthur, find, trendi, 7th, live, sandwich, romant, chees, mac, goat, la, hype, langer, chicago, deli, canter, n, dish, portillo, dog, \n",
      "\n",
      "\n",
      "\n",
      "pork, chicken, beef, rib, waffl, corn, belli, pull, sage, italian, brisket, cheek, tender, brais, short, loui, juici, st., taco, kobe, dri, flavor, fish, pastor, snapper, al, slider, meat, de, moist, panza, red, shoulder, tostada, \n",
      "\n",
      "\n",
      "\n",
      "shrimp, oyster, egg, sauc, bread, rye, benedict, neptun, poach, bacon, fresh, toast, russian, scrambl, tomato, pastrami, hollandais, french, dress, swiss, crunchi, slaw, thick, onion, coleslaw, dip, dumpl, soup, 19, ball, matzo, potato, soft, crust, vanilla, \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Aspect Words (Expanded)\n",
    "f = open(savefilepath, \"r\")\n",
    "for l in f:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  303   734  1509  1876  2377  2685  3292  3790  5360  6538  6766  7840\n",
      "  8181  8434  8993  9992 10002 10735 11387 11897 12017]\n",
      "(5, 21)\n"
     ]
    }
   ],
   "source": [
    "print(data.Restaurants[0].Reviews[0].UniWord)\n",
    "print(data.Restaurants[0].Reviews[0].W.shape) ## 5개 aspects * 21개 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.09090909 0.04545455 0.04545455 0.04545455 0.04545455 0.04545455\n",
      " 0.04545455 0.04545455 0.04545455]\n"
     ]
    }
   ],
   "source": [
    "print(data.Restaurants[0].Reviews[0].W[4])  ## 이 리뷰는 4번 topic에 대한 점수만 가지고 있음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 1. 1. 1. 1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(data.Restaurants[0].Reviews[0].num_stn_aspect_word)\n",
    "## 이건 언제 계산되었나? collect_stat_for_each_review 에서 계산됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  303,   734,  1509,  1876,  2377,  2685,  3292,  3790,  5360,\n",
       "        6538,  6766,  7840,  8181,  8434,  8993,  9992, 10002, 10735,\n",
       "       11387, 11897, 12017])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating W matrix for Restaurant 1\n",
      "Creating W matrix for Restaurant 2\n",
      "Creating W matrix for Restaurant 3\n",
      "Creating W matrix for Restaurant 4\n",
      "Creating W matrix for Restaurant 5\n",
      "Creating W matrix for Restaurant 6\n",
      "Creating W matrix for Restaurant 7\n",
      "Creating W matrix for Restaurant 8\n",
      "Creating W matrix for Restaurant 9\n",
      "Creating W matrix for Restaurant 10\n",
      "Creating W matrix for Restaurant 11\n",
      "Creating W matrix for Restaurant 12\n",
      "Creating W matrix for Restaurant 13\n",
      "Creating W matrix for Restaurant 14\n",
      "Creating W matrix for Restaurant 15\n",
      "Creating W matrix for Restaurant 16\n",
      "Creating W matrix for Restaurant 17\n",
      "Creating W matrix for Restaurant 18\n",
      "Creating W matrix for Restaurant 19\n",
      "Creating W matrix for Restaurant 20\n",
      "Creating W matrix for Restaurant 21\n",
      "Creating W matrix for Restaurant 22\n",
      "Creating W matrix for Restaurant 23\n",
      "Creating W matrix for Restaurant 24\n",
      "Creating W matrix for Restaurant 25\n",
      "Creating W matrix for Restaurant 26\n",
      "Creating W matrix for Restaurant 27\n",
      "TotalNumOfRest =27\n",
      "\n",
      "TotalNumOfReviews =48079\n",
      "\n",
      "TotalNumOfAnnotatedReviews =48079\n",
      "\n",
      "StnsperReview=6.1318455042742155+-4.764547589496152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_all_W(BSanalyzer, data)\n",
    "W_outputfolderpath = \"./output/\"\n",
    "produce_data_for_rating(BSanalyzer, data, W_outputfolderpath)\n",
    "\n",
    "print_summary_stats(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12311,)\n",
      "(5, 12311)\n"
     ]
    }
   ],
   "source": [
    "print(data.all_num_stn_word.shape) ##12,311 단어들\n",
    "print(data.all_num_stn_aspect_word.shape) ## aspect * words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 2., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1.])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Restaurants[0].Reviews[0].num_stn_word  ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({7840: 1, 8993: 1, 8181: 1, 11897: 1, 6766: 1, 303: 1})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Restaurants[0].Reviews[0].Stns[0].stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying LDA -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## doc-term matrix\n",
    "## doc은 1개의 review. multiple sentences 로 구성됨. \n",
    "## 단어는 data.VocabDict에서 숫자로 치환할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "2171\n"
     ]
    }
   ],
   "source": [
    "# print(data.NumOfRestaurants)\n",
    "# print(data.Restaurants[0].NumOfReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_reviews_tot = 0\n",
    "# for rest in (data.Restaurants):\n",
    "#     num_reviews_tot += rest.NumOfReviews\n",
    "# print(num_reviews_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_doc_term_matrix(corpus):\n",
    "#     doc_term_tmp = np.zeros((num_reviews_tot, len(vocab_lda)))\n",
    "#     i = 0\n",
    "#     for rest in corpus.Restaurants:       \n",
    "#         for review in rest.Reviews:\n",
    "#             for stn in review.Stns:\n",
    "#     #             print(stn.stn)\n",
    "#                 for key in stn.stn:\n",
    "#                     value = stn.stn[key]\n",
    "#     #                 print(key)\n",
    "#                     doc_term_tmp[i][key-1] += value\n",
    "#     #                 if i % 100 == 0 :\n",
    "#     #                     print(i)\n",
    "#             i += 1\n",
    "#     return doc_term_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48079, 12311)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_term = np.zeros((num_reviews_tot, len(vocab_lda)))\n",
    "# doc_term.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# test = create_doc_term_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "145\n",
      "2636481\n"
     ]
    }
   ],
   "source": [
    "# print(sum(test[0] != 0))\n",
    "# print(sum(test[1] != 0))\n",
    "# print(sum(test[2] != 0))\n",
    "# print(sum(sum(test != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48079, 12311)\n"
     ]
    }
   ],
   "source": [
    "# print(test.shape)\n",
    "# test_int = test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lda.LDA(n_topics=20, n_iter=1500, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lda:n_documents: 48079\n",
      "INFO:lda:vocab_size: 12311\n",
      "INFO:lda:n_words: 3221134\n",
      "INFO:lda:n_topics: 20\n",
      "INFO:lda:n_iter: 1500\n",
      "WARNING:lda:all zero row in document-term matrix found\n",
      "INFO:lda:<0> log likelihood: -35301802\n",
      "INFO:lda:<10> log likelihood: -28582158\n",
      "INFO:lda:<20> log likelihood: -26795784\n",
      "INFO:lda:<30> log likelihood: -26149864\n",
      "INFO:lda:<40> log likelihood: -25828209\n",
      "INFO:lda:<50> log likelihood: -25644433\n",
      "INFO:lda:<60> log likelihood: -25531822\n",
      "INFO:lda:<70> log likelihood: -25457416\n",
      "INFO:lda:<80> log likelihood: -25396193\n",
      "INFO:lda:<90> log likelihood: -25360910\n",
      "INFO:lda:<100> log likelihood: -25331652\n",
      "INFO:lda:<110> log likelihood: -25307320\n",
      "INFO:lda:<120> log likelihood: -25283951\n",
      "INFO:lda:<130> log likelihood: -25273614\n",
      "INFO:lda:<140> log likelihood: -25260131\n",
      "INFO:lda:<150> log likelihood: -25248366\n",
      "INFO:lda:<160> log likelihood: -25243735\n",
      "INFO:lda:<170> log likelihood: -25230737\n",
      "INFO:lda:<180> log likelihood: -25235502\n",
      "INFO:lda:<190> log likelihood: -25219682\n",
      "INFO:lda:<200> log likelihood: -25218154\n",
      "INFO:lda:<210> log likelihood: -25208612\n",
      "INFO:lda:<220> log likelihood: -25205830\n",
      "INFO:lda:<230> log likelihood: -25203793\n",
      "INFO:lda:<240> log likelihood: -25203711\n",
      "INFO:lda:<250> log likelihood: -25201042\n",
      "INFO:lda:<260> log likelihood: -25202321\n",
      "INFO:lda:<270> log likelihood: -25194405\n",
      "INFO:lda:<280> log likelihood: -25196208\n",
      "INFO:lda:<290> log likelihood: -25193009\n",
      "INFO:lda:<300> log likelihood: -25189954\n",
      "INFO:lda:<310> log likelihood: -25189814\n",
      "INFO:lda:<320> log likelihood: -25187613\n",
      "INFO:lda:<330> log likelihood: -25186681\n",
      "INFO:lda:<340> log likelihood: -25190292\n",
      "INFO:lda:<350> log likelihood: -25186593\n",
      "INFO:lda:<360> log likelihood: -25185116\n",
      "INFO:lda:<370> log likelihood: -25187295\n",
      "INFO:lda:<380> log likelihood: -25182112\n",
      "INFO:lda:<390> log likelihood: -25177922\n",
      "INFO:lda:<400> log likelihood: -25177954\n",
      "INFO:lda:<410> log likelihood: -25171418\n",
      "INFO:lda:<420> log likelihood: -25174411\n",
      "INFO:lda:<430> log likelihood: -25174341\n",
      "INFO:lda:<440> log likelihood: -25177691\n",
      "INFO:lda:<450> log likelihood: -25174301\n",
      "INFO:lda:<460> log likelihood: -25171563\n",
      "INFO:lda:<470> log likelihood: -25173924\n",
      "INFO:lda:<480> log likelihood: -25172439\n",
      "INFO:lda:<490> log likelihood: -25174167\n",
      "INFO:lda:<500> log likelihood: -25172027\n",
      "INFO:lda:<510> log likelihood: -25171429\n",
      "INFO:lda:<520> log likelihood: -25166881\n",
      "INFO:lda:<530> log likelihood: -25167959\n",
      "INFO:lda:<540> log likelihood: -25162295\n",
      "INFO:lda:<550> log likelihood: -25163579\n",
      "INFO:lda:<560> log likelihood: -25165546\n",
      "INFO:lda:<570> log likelihood: -25164381\n",
      "INFO:lda:<580> log likelihood: -25160995\n",
      "INFO:lda:<590> log likelihood: -25157318\n",
      "INFO:lda:<600> log likelihood: -25158751\n",
      "INFO:lda:<610> log likelihood: -25161115\n",
      "INFO:lda:<620> log likelihood: -25160924\n",
      "INFO:lda:<630> log likelihood: -25157091\n",
      "INFO:lda:<640> log likelihood: -25160670\n",
      "INFO:lda:<650> log likelihood: -25160612\n",
      "INFO:lda:<660> log likelihood: -25161900\n",
      "INFO:lda:<670> log likelihood: -25151667\n",
      "INFO:lda:<680> log likelihood: -25163188\n",
      "INFO:lda:<690> log likelihood: -25155972\n",
      "INFO:lda:<700> log likelihood: -25157975\n",
      "INFO:lda:<710> log likelihood: -25157214\n",
      "INFO:lda:<720> log likelihood: -25153737\n",
      "INFO:lda:<730> log likelihood: -25154128\n",
      "INFO:lda:<740> log likelihood: -25159551\n",
      "INFO:lda:<750> log likelihood: -25154980\n",
      "INFO:lda:<760> log likelihood: -25151215\n",
      "INFO:lda:<770> log likelihood: -25148289\n",
      "INFO:lda:<780> log likelihood: -25151619\n",
      "INFO:lda:<790> log likelihood: -25149407\n",
      "INFO:lda:<800> log likelihood: -25145951\n",
      "INFO:lda:<810> log likelihood: -25148223\n",
      "INFO:lda:<820> log likelihood: -25151292\n",
      "INFO:lda:<830> log likelihood: -25150612\n",
      "INFO:lda:<840> log likelihood: -25151526\n",
      "INFO:lda:<850> log likelihood: -25143493\n",
      "INFO:lda:<860> log likelihood: -25153361\n",
      "INFO:lda:<870> log likelihood: -25144266\n",
      "INFO:lda:<880> log likelihood: -25148822\n",
      "INFO:lda:<890> log likelihood: -25147771\n",
      "INFO:lda:<900> log likelihood: -25144762\n",
      "INFO:lda:<910> log likelihood: -25149299\n",
      "INFO:lda:<920> log likelihood: -25147249\n",
      "INFO:lda:<930> log likelihood: -25147963\n",
      "INFO:lda:<940> log likelihood: -25144408\n",
      "INFO:lda:<950> log likelihood: -25145667\n",
      "INFO:lda:<960> log likelihood: -25140247\n",
      "INFO:lda:<970> log likelihood: -25142902\n",
      "INFO:lda:<980> log likelihood: -25143309\n",
      "INFO:lda:<990> log likelihood: -25143733\n",
      "INFO:lda:<1000> log likelihood: -25143092\n",
      "INFO:lda:<1010> log likelihood: -25144208\n",
      "INFO:lda:<1020> log likelihood: -25148838\n",
      "INFO:lda:<1030> log likelihood: -25144844\n",
      "INFO:lda:<1040> log likelihood: -25142321\n",
      "INFO:lda:<1050> log likelihood: -25144927\n",
      "INFO:lda:<1060> log likelihood: -25139675\n",
      "INFO:lda:<1070> log likelihood: -25140809\n",
      "INFO:lda:<1080> log likelihood: -25138478\n",
      "INFO:lda:<1090> log likelihood: -25142844\n",
      "INFO:lda:<1100> log likelihood: -25140899\n",
      "INFO:lda:<1110> log likelihood: -25144335\n",
      "INFO:lda:<1120> log likelihood: -25144250\n",
      "INFO:lda:<1130> log likelihood: -25144721\n",
      "INFO:lda:<1140> log likelihood: -25147188\n",
      "INFO:lda:<1150> log likelihood: -25143381\n",
      "INFO:lda:<1160> log likelihood: -25147624\n",
      "INFO:lda:<1170> log likelihood: -25147348\n",
      "INFO:lda:<1180> log likelihood: -25149820\n",
      "INFO:lda:<1190> log likelihood: -25146885\n",
      "INFO:lda:<1200> log likelihood: -25141584\n",
      "INFO:lda:<1210> log likelihood: -25140497\n",
      "INFO:lda:<1220> log likelihood: -25143015\n",
      "INFO:lda:<1230> log likelihood: -25138840\n",
      "INFO:lda:<1240> log likelihood: -25144542\n",
      "INFO:lda:<1250> log likelihood: -25146204\n",
      "INFO:lda:<1260> log likelihood: -25142144\n",
      "INFO:lda:<1270> log likelihood: -25140049\n",
      "INFO:lda:<1280> log likelihood: -25142505\n",
      "INFO:lda:<1290> log likelihood: -25143618\n",
      "INFO:lda:<1300> log likelihood: -25144271\n",
      "INFO:lda:<1310> log likelihood: -25142482\n",
      "INFO:lda:<1320> log likelihood: -25139270\n",
      "INFO:lda:<1330> log likelihood: -25141367\n",
      "INFO:lda:<1340> log likelihood: -25139537\n",
      "INFO:lda:<1350> log likelihood: -25143924\n",
      "INFO:lda:<1360> log likelihood: -25142603\n",
      "INFO:lda:<1370> log likelihood: -25136232\n",
      "INFO:lda:<1380> log likelihood: -25140286\n",
      "INFO:lda:<1390> log likelihood: -25140733\n",
      "INFO:lda:<1400> log likelihood: -25138809\n",
      "INFO:lda:<1410> log likelihood: -25140250\n",
      "INFO:lda:<1420> log likelihood: -25140696\n",
      "INFO:lda:<1430> log likelihood: -25140644\n",
      "INFO:lda:<1440> log likelihood: -25141640\n",
      "INFO:lda:<1450> log likelihood: -25139113\n",
      "INFO:lda:<1460> log likelihood: -25140687\n",
      "INFO:lda:<1470> log likelihood: -25141779\n",
      "INFO:lda:<1480> log likelihood: -25143771\n",
      "INFO:lda:<1490> log likelihood: -25139438\n",
      "INFO:lda:<1499> log likelihood: -25140521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lda.lda.LDA at 0x1777a9fd0>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(test_int)  # model.fit_transform(X) is also available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: lobstah role oy waistlin pla nephew goo buttah\n",
      "Topic 1: cocain pore goo fret greasiest alli nevertheless foo\n",
      "Topic 2: urth waistlin tabasco n'chees ordeal minuscul foo tim\n",
      "Topic 3: tha foo disgustingli besid restaraunt pla current veg\n",
      "Topic 4: ongo soundtrack dumpi goo fremont cheerwin disgustingli socal\n",
      "Topic 5: chocohol hostil despit goo n'chees dinki ordeal cheerwin\n",
      "Topic 6: cantanker delet sandwhich soundtrack goo pla balk n'chees\n",
      "Topic 7: doesnt hostil chica pla bee fret goo porter\n",
      "Topic 8: chick foo portillo waffel gnosh harvest hug pla\n",
      "Topic 9: bbblt brisk ri goo pla cheerwin sickli pore\n",
      "Topic 10: n'chees lightweight once.i knockout saw eastsid revers 'que\n",
      "Topic 11: chick wine/b saturday fret goo ordeal n'chees crisi\n",
      "Topic 12: steadili waistlin greasiest measur pla byo-win n'chees windshield\n",
      "Topic 13: foo greasiest pla goo server/bartend restaraunt drill lovabl\n",
      "Topic 14: tackl stapl bife goo drill pla greasiest n'chees\n",
      "Topic 15: n'chees goo lightweight foo pla realiz .- stapl\n",
      "Topic 16: pla foo n'chees gestur gnosh tim greasiest goo\n",
      "Topic 17: flava lightweight tasso disgustingli saturday serrano swedish measur\n",
      "Topic 18: pastor- sandwhich lane 18th ryan brea besid n'chees\n",
      "Topic 19: eg fremont to.th brulè breaker goo panang waistlin\n"
     ]
    }
   ],
   "source": [
    "# topic_word = model.topic_word_  # model.components_ also works\n",
    "# n_top_words = 8\n",
    "# for i, topic_dist in enumerate(topic_word):\n",
    "#     topic_words = np.array(vocab_lda)[np.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "#     print('Topic {}: {}'.format(i, ' '.join(topic_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_topic = model.doc_topic_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48079, 20)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_topic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_topic[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({7840: 1, 8993: 1, 8181: 1, 11897: 1, 6766: 1, 303: 1})"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.Restaurants[0].Reviews[0].Stns[0].stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pastrami\n",
      "real\n",
      "way\n",
      "19\n",
      "make\n",
      "one\n"
     ]
    }
   ],
   "source": [
    "# for word, val in data.VocabDict.items(): #mydict에 아이템을 하나씩 접근해서, key, value를 각각 name, age에 저장\n",
    "#     if val in [7840, 8993, 8181, 11897, 6766, 303]:\n",
    "#         print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래는 이해를 돕기 위한 예제 ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Restaurants[0].Reviews[0].Stns[0].stn.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.probability.FreqDist"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data.Restaurants[0].Reviews[0].Stns[0].stn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function FreqDist.values>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Restaurants[0].Reviews[0].Stns[0].stn.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7840\n",
      "1\n",
      "8993\n",
      "1\n",
      "8181\n",
      "1\n",
      "11897\n",
      "1\n",
      "6766\n",
      "1\n",
      "303\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for key in data.Restaurants[0].Reviews[0].Stns[0].stn:\n",
    "    print(key)\n",
    "    print(data.Restaurants[0].Reviews[0].Stns[0].stn[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for values in data.Restaurants[0].Reviews[0].Stns[0].stn.values():\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Restaurants[0].Reviews[0].Stns[0].stn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m4G-dbXxrF6pzEuIj7vZpw\n"
     ]
    }
   ],
   "source": [
    "print(data.Restaurants[0].Reviews[0].ReviewID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 6 samples and 6 outcomes>\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(data.Restaurants[0].Reviews[0].Stns[0].stn)\n",
    "print(data.Restaurants[0].Reviews[0].Stns[0].unilength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8993\n",
      "None\n",
      "8181\n"
     ]
    }
   ],
   "source": [
    "print(data.VocabDict.get('real'))\n",
    "print(data.VocabDict.get('MVPs'))\n",
    "print(data.VocabDict.get('pastrami'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pastrami\n",
      "real\n",
      "way\n",
      "19\n",
      "make\n",
      "one\n"
     ]
    }
   ],
   "source": [
    "for word, val in data.VocabDict.items(): #mydict에 아이템을 하나씩 접근해서, key, value를 각각 name, age에 저장\n",
    "    if val in [7840, 8993, 8181, 11897, 6766, 303]:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예제 END ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
